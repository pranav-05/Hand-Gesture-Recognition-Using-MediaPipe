{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90cdad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import pyttsx3\n",
    "engine = pyttsx3.init()\n",
    "engine.setProperty('rate',200)\n",
    "voice_id = \"HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Speech\\Voices\\Tokens\\TTS_MS_EN-US_ZIRA_11.0\"\n",
    "engine.setProperty('voice', voice_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88454cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the mediapipe hands class.\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# Set up the Hands functions for images and videos.\n",
    "hands = mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.7)\n",
    "hands_videos = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.7)\n",
    "\n",
    "# Initialize the mediapipe drawing class.\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1a3929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectHandsLandmarks(image, hands, draw=True, display = True):\n",
    "    '''\n",
    "    This function performs hands landmarks detection on an image.\n",
    "    Args:\n",
    "        image:   The input image with prominent hand(s) whose landmarks needs to be detected.\n",
    "        hands:   The Hands function required to perform the hands landmarks detection.\n",
    "        draw:    A boolean value that is if set to true the function draws hands landmarks on the output image. \n",
    "        display: A boolean value that is if set to true the function displays the original input image, and the output \n",
    "                 image with hands landmarks drawn if it was specified and returns nothing.\n",
    "    Returns:\n",
    "        output_image: A copy of input image with the detected hands landmarks drawn if it was specified.\n",
    "        results:      The output of the hands landmarks detection on the input image.\n",
    "    '''\n",
    "    \n",
    "    # Create a copy of the input image to draw landmarks on.\n",
    "    output_image = image.copy()\n",
    "    \n",
    "    # Convert the image from BGR into RGB format.\n",
    "    imgRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Perform the Hands Landmarks Detection.\n",
    "    results = hands.process(imgRGB)\n",
    "    \n",
    "    # Check if landmarks are found and are specified to be drawn.\n",
    "    if results.multi_hand_landmarks and draw:\n",
    "        \n",
    "        # Iterate over the found hands.\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            \n",
    "            # Draw the hand landmarks on the copy of the input image.\n",
    "            mp_drawing.draw_landmarks(image = output_image, landmark_list = hand_landmarks,\n",
    "                                      connections = mp_hands.HAND_CONNECTIONS,\n",
    "                                      landmark_drawing_spec=mp_drawing.DrawingSpec(color=(255,255,255),\n",
    "                                                                                   thickness=2, circle_radius=2))\n",
    "    \n",
    "    # Check if the original input image and the output image are specified to be displayed.\n",
    "    if display:\n",
    "        \n",
    "        # Display the original input image and the output image.\n",
    "        plt.figure(figsize=[15,15])\n",
    "        plt.subplot(121);plt.imshow(image[:,:,::-1]);plt.title(\"Original Image\");plt.axis('off');\n",
    "        #image[height:width:depth:slicing of which image to display]->This is for 3D images gives 3D array\n",
    "        plt.subplot(122);plt.imshow(output_image[:,:,::-1]);plt.title(\"Output\");plt.axis('off');\n",
    "        \n",
    "    # Otherwise\n",
    "    else:\n",
    "        \n",
    "        # Return the output image and results of hands landmarks detection.\n",
    "        return output_image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1526413",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countFingers(image, results, draw=True, display=True):\n",
    "    '''\n",
    "    This function will count the number of fingers up for each hand in the image.\n",
    "    Args:\n",
    "        image:   The image of the hands on which the fingers counting is required to be performed.\n",
    "        results: The output of the hands landmarks detection performed on the image of the hands.\n",
    "        draw:    A boolean value that is if set to true the function writes the total count of fingers of the hands on the\n",
    "                 output image.\n",
    "        display: A boolean value that is if set to true the function displays the resultant image and returns nothing.\n",
    "    Returns:\n",
    "        output_image:     A copy of the input image with the fingers count written, if it was specified.\n",
    "        fingers_statuses: A dictionary containing the status (i.e., open or close) of each finger of both hands.\n",
    "        count:            A dictionary containing the count of the fingers that are up, of both hands.\n",
    "    '''\n",
    "    \n",
    "    # Get the height and width of the input image.\n",
    "    height, width, _ = image.shape\n",
    "    \n",
    "    # Create a copy of the input image to write the count of fingers on.\n",
    "    output_image = image.copy()\n",
    "    \n",
    "    # Initialize a dictionary to store the count of fingers of both hands.\n",
    "    count = {'RIGHT': 0, 'LEFT': 0}\n",
    "    \n",
    "    # Store the indexes of the tips landmarks of each finger of a hand in a list.\n",
    "    fingers_tips_ids = [mp_hands.HandLandmark.INDEX_FINGER_TIP, mp_hands.HandLandmark.MIDDLE_FINGER_TIP,\n",
    "                        mp_hands.HandLandmark.RING_FINGER_TIP, mp_hands.HandLandmark.PINKY_TIP]\n",
    "    \n",
    "    # Initialize a dictionary to store the status (i.e., True for open and False for close) of each finger of both hands.\n",
    "    fingers_statuses = {'RIGHT_THUMB': False, 'RIGHT_INDEX': False, 'RIGHT_MIDDLE': False, 'RIGHT_RING': False,\n",
    "                        'RIGHT_PINKY': False, 'LEFT_THUMB': False, 'LEFT_INDEX': False, 'LEFT_MIDDLE': False,\n",
    "                        'LEFT_RING': False, 'LEFT_PINKY': False}\n",
    "    \n",
    "    \n",
    "    # Iterate over the found hands in the image.\n",
    "    for hand_index, hand_info in enumerate(results.multi_handedness):\n",
    "        \n",
    "        # Retrieve the label of the found hand.\n",
    "        hand_label = hand_info.classification[0].label\n",
    "        \n",
    "        # Retrieve the landmarks of the found hand.\n",
    "        hand_landmarks =  results.multi_hand_landmarks[hand_index]\n",
    "        \n",
    "        # Iterate over the indexes of the tips landmarks of each finger of the hand.\n",
    "        for tip_index in fingers_tips_ids:\n",
    "            \n",
    "            # Retrieve the label (i.e., index, middle, etc.) of the finger on which we are iterating upon.\n",
    "            finger_name = tip_index.name.split(\"_\")[0]\n",
    "            \n",
    "            # Check if the finger is up by comparing the y-coordinates of the tip and pip landmarks.\n",
    "            if (hand_landmarks.landmark[tip_index].y < hand_landmarks.landmark[tip_index - 2].y):\n",
    "                \n",
    "                # Update the status of the finger in the dictionary to true.\n",
    "                fingers_statuses[hand_label.upper()+\"_\"+finger_name] = True\n",
    "                \n",
    "                # Increment the count of the fingers up of the hand by 1.\n",
    "                count[hand_label.upper()] += 1\n",
    "        \n",
    "        # Retrieve the y-coordinates of the tip and mcp landmarks of the thumb of the hand.\n",
    "        thumb_tip_x = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP].x\n",
    "        thumb_mcp_x = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP - 2].x\n",
    "        \n",
    "        # Check if the thumb is up by comparing the hand label and the x-coordinates of the retrieved landmarks.\n",
    "        if (hand_label=='Right' and (thumb_tip_x < thumb_mcp_x)) or (hand_label=='Left' and (thumb_tip_x > thumb_mcp_x)):\n",
    "            \n",
    "            # Update the status of the thumb in the dictionary to true.\n",
    "            fingers_statuses[hand_label.upper()+\"_THUMB\"] = True\n",
    "            \n",
    "            # Increment the count of the fingers up of the hand by 1.\n",
    "            count[hand_label.upper()] += 1\n",
    "     \n",
    "    # Check if the total count of the fingers of both hands are specified to be written on the output image.\n",
    "    if draw:\n",
    "\n",
    "        # Write the total count of the fingers of both hands on the output image.\n",
    "        #cv2.putText(output_image, \" Total Fingers: \", (10, 25),cv2.FONT_HERSHEY_COMPLEX, 1, (20,255,155), 2)\n",
    "        cv2.putText(output_image, str(sum(count.values())), (width//150,240), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    5, (20,255,155))\n",
    "\n",
    "    # Check if the output image is specified to be displayed.\n",
    "    if display:\n",
    "        \n",
    "        # Display the output image.\n",
    "        plt.figure(figsize=[10,10])\n",
    "        plt.imshow(output_image[:,:,::-1]);plt.title(\"Output Image\");plt.axis('off');\n",
    "    \n",
    "    # Otherwise\n",
    "    else:\n",
    "\n",
    "        # Return the output image, the status of each finger and the count of the fingers up of both hands.\n",
    "        return output_image, fingers_statuses, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62cf21a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def recognizeGestures(image, fingers_statuses, results, count, draw=True, display=True):\n",
    "    '''\n",
    "    This function will determine the gesture of the left(index=0) and right(index=1) hand in the image.\n",
    "    Args:\n",
    "        image:            The image of the hands on which the hand gesture recognition is required to be performed.\n",
    "        fingers_statuses: A dictionary containing the status (i.e., open or close) of each finger of both hands. \n",
    "        count:            A dictionary containing the count of the fingers that are up, of both hands.\n",
    "        draw:             A boolean value that is if set to true the function writes the gestures of the hands on the\n",
    "                          output image, after recognition.\n",
    "        display:          A boolean value that is if set to true the function displays the resultant image and \n",
    "                          returns nothing.\n",
    "    Returns:\n",
    "        output_image:   A copy of the input image with the left and right hand recognized gestures written if it was \n",
    "                        specified.\n",
    "        hands_gestures: A dictionary containing the recognized gestures of the right and left hand.\n",
    "    '''\n",
    "    \n",
    "    # Create a copy of the input image.\n",
    "    output_image = image.copy()\n",
    "    h, w, c = output_image.shape\n",
    "    finger_tips = [8, 12, 16, 20]\n",
    "    thumb_tip = 4\n",
    "    # Store the labels of both hands in a list.\n",
    "    #label = 'results.multi_handedness[0].classification[0].label'\n",
    "    hands_labels = ['RIGHT']\n",
    "    \n",
    "    # Initialize a dictionary to store the gestures of both hands in the image.\n",
    "    hands_gestures = {'RIGHT': \"UNKNOWN\"}\n",
    "    #hands_gestures1 = {'LEFT':'UNKNOWN'}\n",
    "    \n",
    "    \n",
    "    # Iterate over the left and right hand.\n",
    "    for hand_index, hand_label in enumerate(hands_labels):\n",
    "        \n",
    "        # Initialize a variable to store the color we will use to write the hands gestures on the image.\n",
    "        # Initially it is red which represents that the gesture is not recognized.\n",
    "        color = (0, 0, 255)\n",
    "        \n",
    "          #check if the person is making the 'UNITE' gesture with the hand.\n",
    "        ####################################################################################################################\n",
    "        lm_list2 = []\n",
    "        # Check if the number of fingers up is 0.\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmark in results.multi_hand_landmarks:\n",
    "                \n",
    "                for id, lm in enumerate(hand_landmark.landmark):\n",
    "                    lm_list2.append(lm)\n",
    "                finger_fold_status = []\n",
    "                for tip in finger_tips:\n",
    "                    if lm_list2[tip].y > lm_list2[tip - 3].y:\n",
    "                        finger_fold_status.append(True)\n",
    "                    else:\n",
    "                        finger_fold_status.append(False)\n",
    "                if all(finger_fold_status):\n",
    "                    if lm_list2[thumb_tip].x > lm_list2[thumb_tip - 1].x > lm_list2[thumb_tip - 2].x:\n",
    "                        hands_gestures[hand_label]=\"UNITE\"\n",
    "                        print(\"UNITE\")\n",
    "                        color=(0,255,0)\n",
    "                        engine.say(\"UNITE\")\n",
    "                        engine.runAndWait()\n",
    "                        engine.stop()\n",
    "                        #cv2.putText(output_image,\"UNITE\" , (10, (hand_index+1) * 60),cv2.FONT_HERSHEY_PLAIN, 4, color, 5)\n",
    "        \n",
    "        # Check if the person is making the 'VICTORY' gesture with the hand.\n",
    "        ####################################################################################################################\n",
    "        \n",
    "        # Check if the number of fingers up is 2 and the fingers that are up, are the index and the middle finger.\n",
    "        if count[hand_label] == 2  and fingers_statuses[hand_label+'_MIDDLE'] and fingers_statuses[hand_label+'_INDEX']:\n",
    "            \n",
    "            # Update the gesture value of the hand that we are iterating upon to V SIGN.\n",
    "            \n",
    "            hands_gestures[hand_label] = \"VICTORY\"\n",
    "            \n",
    "            # Update the color value to green.\n",
    "            color=(0,255,0)\n",
    "            engine.say(\"Victory\")\n",
    "            engine.runAndWait()\n",
    "            engine.stop()\n",
    "            \n",
    "        ####################################################################################################################            \n",
    "        \n",
    "         # Check if the person is making the 'CALL ME' gesture with the hand.\n",
    "        ####################################################################################################################\n",
    "        \n",
    "        # Check if the number of fingers up is 2 and the fingers that are up, are the pinky and the thumb.\n",
    "        if count[hand_label] == 2  and fingers_statuses[hand_label+'_THUMB'] and fingers_statuses[hand_label+'_PINKY']:\n",
    "            \n",
    "            # Update the gesture value of the hand that we are iterating upon to call me.\n",
    "            hands_gestures[hand_label] = \"CALL ME\"\n",
    "            \n",
    "            # Update the color value to green.\n",
    "            color=(0,255,0)\n",
    "            engine.say(\"CALL ME\")\n",
    "            engine.runAndWait()\n",
    "            engine.stop()\n",
    "         ##########################################################################################################################################################\n",
    "        \n",
    "        \n",
    "        # Check if the person is making the 'ROCK ON' gesture with the hand.\n",
    "        ##########################################################################################################################################################\n",
    "        \n",
    "        # Check if the number of fingers up is 3 and the fingers that are up, are the thumb, index and the pinky finger.\n",
    "        if count[hand_label] == 3 and fingers_statuses[hand_label+'_THUMB'] and fingers_statuses[hand_label+'_INDEX'] and fingers_statuses[hand_label+'_PINKY']:\n",
    "                \n",
    "            # Update the gesture value of the hand that we are iterating upon to SPIDERMAN SIGN.\n",
    "            hands_gestures[hand_label] = \"ROCK ON\"\n",
    "\n",
    "            # Update the color value to green.\n",
    "            color=(0,255,0)\n",
    "            engine.say(\"ROCK ON\")\n",
    "            engine.runAndWait()\n",
    "            engine.stop()\n",
    "                \n",
    "        ##########################################################################################################################################################\n",
    "        \n",
    "        \n",
    "         # Check if the person is making the 'PEACE' gesture with the hand.\n",
    "        ##########################################################################################################################################################\n",
    "        \n",
    "        # Check if the number of fingers up is 3 and the fingers that are up, are the thumb, index and the pinky finger.\n",
    "        if count[hand_label] == 3 and fingers_statuses[hand_label+'_INDEX'] and fingers_statuses[hand_label+'_MIDDLE'] and fingers_statuses[hand_label+'_RING']:\n",
    "                \n",
    "            # Update the gesture value of the hand that we are iterating upon to SPIDERMAN SIGN.\n",
    "            hands_gestures[hand_label] = \"PEACE\"\n",
    "\n",
    "            # Update the color value to green.\n",
    "            color=(0,255,0)\n",
    "            engine.say(\"PEACE\")\n",
    "            engine.runAndWait()\n",
    "            engine.stop()\n",
    "                \n",
    "        ##########################################################################################################################################################\n",
    "        \n",
    "        \n",
    "        # Check if the person is making the 'HELLO' gesture with the hand.\n",
    "        ####################################################################################################################\n",
    "        \n",
    "        # Check if the number of fingers up is 5, which means that all the fingers are up.\n",
    "        if count[hand_label] == 5:\n",
    "            \n",
    "            # Update the gesture value of the hand that we are iterating upon to HIGH-FIVE SIGN.\n",
    "            hands_gestures[hand_label] = \"HELLO\"\n",
    "            \n",
    "            # Update the color value to green.\n",
    "            color=(0,255,0)\n",
    "            engine.say(\"HELLO\")\n",
    "            engine.runAndWait()\n",
    "            engine.stop()\n",
    "       \n",
    "        ####################################################################################################################  \n",
    "\n",
    "        # Check if the person is making the 'THUMBS UP' and 'THUMBS DOWN' gesture with the hand.\n",
    "        ####################################################################################################################\n",
    "        lm_list = []\n",
    "        # Check if the number of fingers up is 1, which means THUMB is up\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmark in results.multi_hand_landmarks:    \n",
    "                for id, lm in enumerate(hand_landmark.landmark):\n",
    "                    lm_list.append(lm)\n",
    "                finger_fold_status = []\n",
    "                for tip in finger_tips:\n",
    "                    if lm_list[tip].x < lm_list[tip - 3].x:\n",
    "                        finger_fold_status.append(True)\n",
    "                    else:\n",
    "                        finger_fold_status.append(False)\n",
    "                print(finger_fold_status)\n",
    "                if all(finger_fold_status):\n",
    "                    # thumbs up\n",
    "                    if lm_list[thumb_tip].y < lm_list[thumb_tip - 1].y < lm_list[thumb_tip - 2].y :\n",
    "                        hands_gestures[hand_label]='THUMBS UP'\n",
    "                        print(\"THUMBS UP\")\n",
    "                        color=(0,255,0)\n",
    "                        engine.say(\"THUMBS UP\")\n",
    "                        engine.runAndWait()\n",
    "                        engine.stop()\n",
    "                        #cv2.putText(output_image,\"THUMBS UP\" , (10, (hand_index+1) * 60),\n",
    "                          #          cv2.FONT_HERSHEY_PLAIN, 4, color, 5)\n",
    "\n",
    "                    # Thumbs down\n",
    "                    if lm_list[thumb_tip].y > lm_list[thumb_tip - 1].y > lm_list[thumb_tip - 2].y:\n",
    "                        hands_gestures[hand_label]='THUMBS DOWN'\n",
    "                        #cv2.putText(output_image, \"THUMBS DOWN\" , (10, (hand_index+1) * 60),\n",
    "                         #           cv2.FONT_HERSHEY_PLAIN, 4, color, 5)\n",
    "                        print(\"THUMBS DOWN\")\n",
    "                        color=(0,255,0)\n",
    "                        engine.say(\"THUMBS DOWN\")\n",
    "                        engine.runAndWait()\n",
    "                        engine.stop()\n",
    "                    \n",
    "                    \n",
    "                     # Retrieve the y-coordinates of the tip and mcp landmarks of the thumb of the hand.\n",
    "                    #thumb_tip_x = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP].x\n",
    "                    #thumb_mcp_x = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP - 2].x\n",
    "\n",
    "                    # Check if the thumb is up by comparing the hand label and the x-coordinates of the retrieved landmarks.\n",
    "                    '''\n",
    "                    if ((hands_gestures.items=='Left')):\n",
    "\n",
    "                        if lm_list[tip].x < lm_list[tip - 3].x:\n",
    "                            cv2.circle(output_image, (x, y), 15, (0, 255, 0), cv2.FILLED)\n",
    "                            finger_fold_status.append(True)\n",
    "                            if all(finger_fold_status):\n",
    "                                # THHUMBS UP\n",
    "                                if results.hand_landmarks.landmark[hand_landmark.thumb_tip]:\n",
    "                                    print(\"THUMBS UP\")\n",
    "                                    cv2.putText(output_image, \"THUMBS UP\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (102, 255, 25), 3)\n",
    "                                else:\n",
    "                                    finger_fold_status.append(False)\n",
    "                    '''\n",
    "               \n",
    "                       \n",
    "                    # Dislike\n",
    "                    #if lm_list[thumb_tip].y > lm_list[thumb_tip - 1].y > lm_list[thumb_tip - 2].y:\n",
    "                     #   cv2.putText(output_image, \"THUMBS DOWN\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (102, 255, 25), 3)\n",
    "                \n",
    "       \n",
    "        ####################################################################################################################  \n",
    "        \n",
    "      \n",
    "        #(results.multi_hand_landmarks[0].landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y<results.multi_hand_landmarks[0].landmark[mp_hands.HandLandmark.INDEX_FINGER_MCP].y) and \n",
    "        #(results.multi_hand_landmarks[0].landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP].y<results.multi_hand_landmarks[0].landmark[mp_hands.HandLandmark.MIDDLE_FINGER_MCP].y) and\n",
    "        #(results.multi_hand_landmarks[0].landmark[mp_hands.HandLandmark.RING_FINGER_TIP].y<results.multi_hand_landmarks[0].landmark[mp_hands.HandLandmark.RING_FINGER_MCP].y) and\n",
    "        #(results.multi_hand_landmarks[0].landmark[mp_hands.HandLandmark.PINKY_TIP].y<results.multi_hand_landmarks[0].landmark[mp_hands.HandLandmark.PINKY_MCP].y) and\n",
    "        #(results.multi_hand_landmarks[0].landmark[mp_hands.HandLandmark.INDEX_FINGER_MCP].x<results.multi_hand_landmarks[0].landmark[mp_hands.HandLandmark.THUMB_TIP].y)\n",
    "        \n",
    "           \n",
    "            \n",
    "         ###################################################################################################################  \n",
    "        # Check if the hands gestures are specified to be written.\n",
    "        if draw:\n",
    "            for id, lm in enumerate(results.multi_hand_landmarks):\n",
    "                lm_list.append(lm)\n",
    "                finger_fold_status = []\n",
    "                for tip in finger_tips:\n",
    "                    x, y = int(lm_list[tip].x * w), int(lm_list[tip].y * h)\n",
    "                    if lm_list[tip].x < lm_list[tip - 3].x:\n",
    "                        cv2.circle(output_image, (x, y), 10, (0, 255, 0), cv2.FILLED)\n",
    "                    else:\n",
    "                        cv2.circle(output_image, (x, y), 10, (255, 0, 0), cv2.FILLED)\n",
    "                    #if hands_gestures[hand_label]!= 'UNKNOWN' and results.multi_handedness[0].classification[0].label=='RIGHT':\n",
    "                    cv2.putText(output_image, hands_gestures[hand_label] , (10, (hand_index+1) * 60),cv2.FONT_HERSHEY_PLAIN, 4, color, 5)\n",
    "                    #cv2.putText(output_image, \"Please Wait\" , (10, (hand_index+1) * 60),cv2.FONT_HERSHEY_PLAIN, 4, color, 5)\n",
    "           ################################################################################################################         \n",
    "                    \n",
    "    print(hands_gestures[hand_label])\n",
    "    # Check if the output image is specified to be displayed.\n",
    "    if display:\n",
    "\n",
    "        # Display the output image.\n",
    "        plt.figure(figsize=[10,10])\n",
    "        plt.imshow(output_image[:,:,::-1]);plt.title(\"Output Image\");plt.axis('off');\n",
    "    \n",
    "    # Otherwise\n",
    "    else:\n",
    "\n",
    "        # Return the output image and the gestures of the both hands.\n",
    "        return output_image, hands_gestures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37e911b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True, True, True]\n",
      "THUMBS UP\n",
      "THUMBS UP\n",
      "[True, True, True, True]\n",
      "THUMBS UP\n",
      "THUMBS UP\n",
      "[True, False, False, False]\n",
      "HELLO\n",
      "[True, False, False, False]\n",
      "HELLO\n",
      "UNITE\n",
      "[True, True, True, True]\n",
      "THUMBS UP\n",
      "THUMBS UP\n",
      "[True, True, True, True]\n",
      "THUMBS UP\n",
      "THUMBS UP\n",
      "[True, True, True, False]\n",
      "UNKNOWN\n",
      "[True, False, True, False]\n",
      "ROCK ON\n",
      "[True, False, False, False]\n",
      "ROCK ON\n",
      "[True, True, True, False]\n",
      "CALL ME\n",
      "[False, True, True, False]\n",
      "CALL ME\n",
      "UNITE\n",
      "[False, False, True, True]\n",
      "UNITE\n",
      "UNITE\n",
      "[False, False, True, True]\n",
      "UNITE\n",
      "UNITE\n",
      "[False, False, False, False]\n",
      "UNITE\n",
      "UNITE\n",
      "[False, False, False, False]\n",
      "UNITE\n",
      "UNITE\n",
      "[False, False, False, False]\n",
      "UNITE\n",
      "UNITE\n",
      "[False, False, False, False]\n",
      "UNITE\n",
      "[False, False, False, False]\n",
      "UNKNOWN\n",
      "[False, False, False, False]\n",
      "UNKNOWN\n",
      "[False, False, False, False]\n",
      "UNKNOWN\n",
      "[True, False, False, False]\n",
      "HELLO\n",
      "[True, True, False, False]\n",
      "HELLO\n",
      "[True, True, False, False]\n",
      "HELLO\n",
      "UNITE\n",
      "[False, False, True, True]\n",
      "UNITE\n",
      "UNITE\n",
      "[True, True, True, True]\n",
      "THUMBS UP\n",
      "THUMBS UP\n",
      "[True, False, True, True]\n",
      "VICTORY\n",
      "[True, False, True, True]\n",
      "VICTORY\n",
      "UNITE\n",
      "[False, False, False, False]\n",
      "UNITE\n",
      "[False, False, False, False]\n",
      "UNKNOWN\n",
      "[False, False, False, False]\n",
      "UNKNOWN\n",
      "[False, False, False, False]\n",
      "UNKNOWN\n",
      "UNITE\n",
      "[False, False, False, False]\n",
      "UNITE\n",
      "[False, False, False, False]\n",
      "UNKNOWN\n",
      "[False, False, False, False]\n",
      "UNKNOWN\n",
      "UNITE\n",
      "[False, False, False, False]\n",
      "UNITE\n"
     ]
    }
   ],
   "source": [
    "# Initialize the VideoCapture object to read from the webcam.\n",
    "camera_video = cv2.VideoCapture(0)\n",
    "camera_video.set(3,1280)\n",
    "camera_video.set(4,960)\n",
    "\n",
    "# Create named window for resizing purposes.\n",
    "cv2.namedWindow('Hand Recognizer', cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Iterate until the webcam is accessed successfully.\n",
    "while camera_video.isOpened():\n",
    "    \n",
    "    #time_elapsed = time.time() - prev\n",
    "    # Read a frame.\n",
    "    ok, frame = camera_video.read()\n",
    "    \n",
    "    \n",
    "    # Check if frame is not read properly then continue to the next iteration to read the next frame.\n",
    "    if not ok:\n",
    "        continue\n",
    "        \n",
    "    #if time_elapsed > 1./frame_rate:\n",
    "        #prev = time.time()\n",
    "        # Flip the frame horizontally for natural (selfie-view) visualization.\n",
    "    flipped_image = cv2.flip(frame, 1)\n",
    "        # Perform Hands landmarks detection on the frame.\n",
    "\n",
    "    frame, results = detectHandsLandmarks(flipped_image, hands_videos, display=False)\n",
    "    if results.multi_hand_landmarks:\n",
    "        frame, fingers_statuses, count = countFingers(frame, results, draw=True, display = False)\n",
    "        frame,_ = recognizeGestures(frame, fingers_statuses,results, count,draw=True, display=False)\n",
    "            # Display the frame.\n",
    "    cv2.imshow('Hand Recognizer',frame)\n",
    "\n",
    "        # Wait for 1ms. If a key is pressed, retreive the ASCII code of the key.\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        # Check if 'ESC' is pressed and break the loop.\n",
    "    if(k == 27):\n",
    "        break\n",
    "\n",
    "# Release the VideoCapture Object and close the windows.\n",
    "camera_video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12c4e1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3235e422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index: 0\n",
       "score: 0.990236759185791\n",
       "label: \"Left\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " results.multi_handedness[0].classification[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a451c392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Left'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " results.multi_handedness[0].classification[0].label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d6b9b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
